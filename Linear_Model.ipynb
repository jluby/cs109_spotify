{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "pd.set_option('display.max_columns', 25)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "from collections import Counter\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "pd.set_option('display.width', 1500)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort columns\n",
    "ids = ['track_id', 'album_id']\n",
    "predictors = ['track_number', 'track_count', 'duration', 'explicit', \n",
    "              'danceability', 'energy', 'loudness', 'speechiness', \n",
    "              'acousticness', 'instrumentalness', 'liveness', \n",
    "              'valence', 'tempo']\n",
    "cols = ['track_number', 'track_count', 'duration', 'explicit', 'track_pop', 'album_pop', \n",
    "              'danceability', 'energy', 'loudness', 'speechiness', \n",
    "              'acousticness', 'instrumentalness', 'liveness', \n",
    "              'valence', 'tempo']\n",
    "response = 'comparative_pop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv('data/training.csv')\n",
    "test = pd.read_csv('data/testing.csv')\n",
    "\n",
    "# Regularize\n",
    "# Create a scaler\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "# Fit scaler on data\n",
    "no_id_train = train.drop(['track_id', 'album_id'], axis=1)\n",
    "no_id_test = test.drop(['track_id', 'album_id'], axis=1)\n",
    "scaler.fit(no_id_train)\n",
    "\n",
    "# Apply transform\n",
    "normalized_train = scaler.transform(no_id_train)\n",
    "normalized_test = scaler.transform(no_id_test)\n",
    "\n",
    "# Separate the features from the response\n",
    "X_train = pd.DataFrame(normalized_train[:, :-1], columns = cols)[predictors]\n",
    "y_train = pd.DataFrame(normalized_train[:, -1], columns = [response])\n",
    "\n",
    "X_test = pd.DataFrame(normalized_test[:, :-1], columns = cols)[predictors]\n",
    "y_test = pd.DataFrame(normalized_test[:, -1], columns = [response])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:        comparative_pop   R-squared:                       0.064\n",
      "Model:                            OLS   Adj. R-squared:                  0.064\n",
      "Method:                 Least Squares   F-statistic:                     635.8\n",
      "Date:                Wed, 11 Dec 2019   Prob (F-statistic):               0.00\n",
      "Time:                        19:28:59   Log-Likelihood:                 15755.\n",
      "No. Observations:              120793   AIC:                        -3.148e+04\n",
      "Df Residuals:                  120779   BIC:                        -3.135e+04\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const                0.1160      0.021      5.444      0.000       0.074       0.158\n",
      "track_number        -0.5291      0.008    -62.305      0.000      -0.546      -0.513\n",
      "track_count         -0.2520      0.018    -14.251      0.000      -0.287      -0.217\n",
      "duration             0.3644      0.015     23.726      0.000       0.334       0.394\n",
      "explicit            -0.0113      0.001    -10.638      0.000      -0.013      -0.009\n",
      "danceability         0.0227      0.002     10.222      0.000       0.018       0.027\n",
      "energy               0.0051      0.003      2.008      0.045       0.000       0.010\n",
      "loudness            -0.0520      0.007     -7.292      0.000      -0.066      -0.038\n",
      "speechiness         -0.0200      0.003     -6.003      0.000      -0.026      -0.013\n",
      "acousticness         0.0085      0.001      5.946      0.000       0.006       0.011\n",
      "instrumentalness     0.0024      0.001      1.946      0.052   -1.69e-05       0.005\n",
      "liveness            -0.0123      0.002     -7.009      0.000      -0.016      -0.009\n",
      "valence              0.0257      0.002     16.520      0.000       0.023       0.029\n",
      "tempo                0.0021      0.002      0.847      0.397      -0.003       0.007\n",
      "==============================================================================\n",
      "Omnibus:                     6548.150   Durbin-Watson:                   2.010\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7747.465\n",
      "Skew:                          -0.584   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.418   Cond. No.                         111.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/cs109a/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# simple OLS\n",
    "X_train_const = sm.add_constant(X_train)\n",
    "X_test_const = sm.add_constant(X_test)\n",
    "\n",
    "lin_model = sm.OLS(y_train, X_train_const).fit()\n",
    "print(lin_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training MSE</th>\n",
       "      <th>Test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Model</td>\n",
       "      <td>0.045106</td>\n",
       "      <td>0.045137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Training MSE  Test MSE\n",
       "0  Linear Model      0.045106  0.045137"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get MSEs\n",
    "train_predict = lin_model.predict(X_train_const)\n",
    "test_predict = lin_model.predict(X_test_const)\n",
    "\n",
    "train_score = metrics.mean_squared_error(y_train, train_predict)\n",
    "test_score = metrics.mean_squared_error(y_test, test_predict)\n",
    "\n",
    "pd.DataFrame([[\"Linear Model\", train_score, test_score]], columns = ['Model', 'Training MSE', 'Test MSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/cs109a/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Add polynomial terms to dataset manually\n",
    "X_train_poly = X_train.copy()\n",
    "X_test_poly = X_test.copy()\n",
    "for col in X_train.columns:\n",
    "    X_train_poly[col + \"^2\"] = X_train[col]**2\n",
    "    X_test_poly[col + \"^2\"] = X_test[col]**2\n",
    "    \n",
    "X_train_poly_const = sm.add_constant(X_train_poly)\n",
    "X_test_poly_const = sm.add_constant(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:        comparative_pop   R-squared:                       0.078\n",
      "Model:                            OLS   Adj. R-squared:                  0.078\n",
      "Method:                 Least Squares   F-statistic:                     411.1\n",
      "Date:                Wed, 11 Dec 2019   Prob (F-statistic):               0.00\n",
      "Time:                        19:29:23   Log-Likelihood:            -4.4959e+05\n",
      "No. Observations:              120793   AIC:                         8.992e+05\n",
      "Df Residuals:                  120767   BIC:                         8.995e+05\n",
      "Df Model:                          25                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                 -9.0484      0.532    -17.020      0.000     -10.090      -8.006\n",
      "track_number          -0.5157      0.007    -69.517      0.000      -0.530      -0.501\n",
      "track_count           -0.0852      0.004    -19.159      0.000      -0.094      -0.076\n",
      "duration            1.054e-05   4.15e-07     25.394      0.000    9.72e-06    1.13e-05\n",
      "explicit              -0.5429      0.052    -10.541      0.000      -0.644      -0.442\n",
      "danceability          -1.0276      0.909     -1.130      0.258      -2.809       0.754\n",
      "energy                 1.1560      0.802      1.442      0.149      -0.415       2.727\n",
      "loudness              -0.1103      0.023     -4.838      0.000      -0.155      -0.066\n",
      "speechiness            3.1361      0.708      4.432      0.000       1.749       4.523\n",
      "acousticness           1.3495      0.374      3.610      0.000       0.617       2.082\n",
      "instrumentalness       0.5037      0.529      0.953      0.341      -0.532       1.540\n",
      "liveness              -1.8443      0.514     -3.585      0.000      -2.853      -0.836\n",
      "valence                2.1246      0.515      4.128      0.000       1.116       3.133\n",
      "tempo                  0.0167      0.007      2.425      0.015       0.003       0.030\n",
      "track_number^2         0.0046      0.000     37.647      0.000       0.004       0.005\n",
      "track_count^2          0.0002   2.81e-05      7.612      0.000       0.000       0.000\n",
      "duration^2         -2.651e-12   1.88e-13    -14.078      0.000   -3.02e-12   -2.28e-12\n",
      "explicit^2            -0.5429      0.052    -10.541      0.000      -0.644      -0.442\n",
      "danceability^2         2.7253      0.819      3.329      0.001       1.121       4.330\n",
      "energy^2              -0.6150      0.619     -0.994      0.320      -1.828       0.598\n",
      "loudness^2            -0.0009      0.001     -1.325      0.185      -0.002       0.000\n",
      "speechiness^2         -7.8090      1.073     -7.279      0.000      -9.912      -5.706\n",
      "acousticness^2        -0.2509      0.431     -0.582      0.561      -1.097       0.595\n",
      "instrumentalness^2    -0.3434      0.615     -0.558      0.577      -1.549       0.862\n",
      "liveness^2             1.0838      0.597      1.815      0.070      -0.087       2.254\n",
      "valence^2              0.4101      0.483      0.849      0.396      -0.536       1.356\n",
      "tempo^2            -6.276e-05   2.73e-05     -2.303      0.021      -0.000   -9.34e-06\n",
      "==============================================================================\n",
      "Omnibus:                     6363.752   Durbin-Watson:                   2.011\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7484.977\n",
      "Skew:                          -0.576   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.397   Cond. No.                     1.05e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.05e+16. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Create 2nd degree polynomial terms manually\n",
    "model_poly = sm.OLS(y_train, X_train_poly_const).fit()\n",
    "print(model_poly_man.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training MSE</th>\n",
       "      <th>Test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear w/ 2nd Degree Poly</td>\n",
       "      <td>0.044413</td>\n",
       "      <td>0.044654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Training MSE  Test MSE\n",
       "0  Linear w/ 2nd Degree Poly      0.044413  0.044654"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get MSEs\n",
    "train_predict_poly = model_poly.predict(X_train_poly_const)\n",
    "test_predict_poly = model_poly.predict(X_test_poly_const)\n",
    "\n",
    "train_score_poly = metrics.mean_squared_error(y_train, train_predict_poly)\n",
    "test_score_poly = metrics.mean_squared_error(y_test, test_predict_poly)\n",
    "\n",
    "pd.DataFrame([[\"Linear w/ 2nd Degree Poly\", train_score_poly, test_score_poly]], columns = ['Model', 'Training MSE', 'Test MSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  65 out of  65 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029087</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>25</td>\n",
       "      <td>{'alpha': 25}</td>\n",
       "      <td>-0.044732</td>\n",
       "      <td>-0.044545</td>\n",
       "      <td>-0.044320</td>\n",
       "      <td>-0.044410</td>\n",
       "      <td>-0.044321</td>\n",
       "      <td>-0.044466</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.028843</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "      <td>-0.044709</td>\n",
       "      <td>-0.044520</td>\n",
       "      <td>-0.044310</td>\n",
       "      <td>-0.044376</td>\n",
       "      <td>-0.044314</td>\n",
       "      <td>-0.044446</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025903</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>4</td>\n",
       "      <td>{'alpha': 4}</td>\n",
       "      <td>-0.044700</td>\n",
       "      <td>-0.044509</td>\n",
       "      <td>-0.044313</td>\n",
       "      <td>-0.044361</td>\n",
       "      <td>-0.044318</td>\n",
       "      <td>-0.044440</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025950</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>2</td>\n",
       "      <td>{'alpha': 2}</td>\n",
       "      <td>-0.044697</td>\n",
       "      <td>-0.044505</td>\n",
       "      <td>-0.044317</td>\n",
       "      <td>-0.044355</td>\n",
       "      <td>-0.044321</td>\n",
       "      <td>-0.044439</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.026217</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>-0.044696</td>\n",
       "      <td>-0.044504</td>\n",
       "      <td>-0.044322</td>\n",
       "      <td>-0.044352</td>\n",
       "      <td>-0.044323</td>\n",
       "      <td>-0.044439</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.025829</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'alpha': 0.8}</td>\n",
       "      <td>-0.044696</td>\n",
       "      <td>-0.044504</td>\n",
       "      <td>-0.044324</td>\n",
       "      <td>-0.044352</td>\n",
       "      <td>-0.044323</td>\n",
       "      <td>-0.044440</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.026537</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>-0.044696</td>\n",
       "      <td>-0.044503</td>\n",
       "      <td>-0.044328</td>\n",
       "      <td>-0.044351</td>\n",
       "      <td>-0.044324</td>\n",
       "      <td>-0.044440</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.026201</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 0.3}</td>\n",
       "      <td>-0.044695</td>\n",
       "      <td>-0.044503</td>\n",
       "      <td>-0.044332</td>\n",
       "      <td>-0.044350</td>\n",
       "      <td>-0.044324</td>\n",
       "      <td>-0.044441</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.028216</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'alpha': 0.2}</td>\n",
       "      <td>-0.044695</td>\n",
       "      <td>-0.044503</td>\n",
       "      <td>-0.044334</td>\n",
       "      <td>-0.044350</td>\n",
       "      <td>-0.044325</td>\n",
       "      <td>-0.044441</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.025918</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>-0.044695</td>\n",
       "      <td>-0.044503</td>\n",
       "      <td>-0.044337</td>\n",
       "      <td>-0.044350</td>\n",
       "      <td>-0.044325</td>\n",
       "      <td>-0.044442</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.026195</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'alpha': 0.05}</td>\n",
       "      <td>-0.044695</td>\n",
       "      <td>-0.044503</td>\n",
       "      <td>-0.044338</td>\n",
       "      <td>-0.044349</td>\n",
       "      <td>-0.044325</td>\n",
       "      <td>-0.044442</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.02</td>\n",
       "      <td>{'alpha': 0.02}</td>\n",
       "      <td>-0.044695</td>\n",
       "      <td>-0.044503</td>\n",
       "      <td>-0.044339</td>\n",
       "      <td>-0.044349</td>\n",
       "      <td>-0.044325</td>\n",
       "      <td>-0.044442</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.026123</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>-0.044695</td>\n",
       "      <td>-0.044503</td>\n",
       "      <td>-0.044340</td>\n",
       "      <td>-0.044349</td>\n",
       "      <td>-0.044325</td>\n",
       "      <td>-0.044442</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha           params  split0_test_score  split1_test_score  split2_test_score  split3_test_score  split4_test_score  mean_test_score  std_test_score  rank_test_score\n",
       "0        0.029087      0.003922         0.002467        0.000487          25    {'alpha': 25}          -0.044732          -0.044545          -0.044320          -0.044410          -0.044321        -0.044466        0.000156               13\n",
       "1        0.028843      0.002448         0.002315        0.000238          10    {'alpha': 10}          -0.044709          -0.044520          -0.044310          -0.044376          -0.044314        -0.044446        0.000152               12\n",
       "2        0.025903      0.000926         0.002030        0.000176           4     {'alpha': 4}          -0.044700          -0.044509          -0.044313          -0.044361          -0.044318        -0.044440        0.000148                4\n",
       "3        0.025950      0.000751         0.002042        0.000167           2     {'alpha': 2}          -0.044697          -0.044505          -0.044317          -0.044355          -0.044321        -0.044439        0.000146                1\n",
       "4        0.026217      0.000835         0.002065        0.000140           1   {'alpha': 1.0}          -0.044696          -0.044504          -0.044322          -0.044352          -0.044323        -0.044439        0.000145                2\n",
       "5        0.025829      0.000453         0.002043        0.000155         0.8   {'alpha': 0.8}          -0.044696          -0.044504          -0.044324          -0.044352          -0.044323        -0.044440        0.000144                3\n",
       "6        0.026537      0.000877         0.002068        0.000144         0.5   {'alpha': 0.5}          -0.044696          -0.044503          -0.044328          -0.044351          -0.044324        -0.044440        0.000144                5\n",
       "7        0.026201      0.000510         0.002025        0.000119         0.3   {'alpha': 0.3}          -0.044695          -0.044503          -0.044332          -0.044350          -0.044324        -0.044441        0.000143                6\n",
       "8        0.028216      0.001747         0.002145        0.000180         0.2   {'alpha': 0.2}          -0.044695          -0.044503          -0.044334          -0.044350          -0.044325        -0.044441        0.000143                7\n",
       "9        0.025918      0.000454         0.001936        0.000057         0.1   {'alpha': 0.1}          -0.044695          -0.044503          -0.044337          -0.044350          -0.044325        -0.044442        0.000142                8\n",
       "10       0.026195      0.000728         0.002140        0.000189        0.05  {'alpha': 0.05}          -0.044695          -0.044503          -0.044338          -0.044349          -0.044325        -0.044442        0.000142                9\n",
       "11       0.025900      0.000679         0.001975        0.000134        0.02  {'alpha': 0.02}          -0.044695          -0.044503          -0.044339          -0.044349          -0.044325        -0.044442        0.000142               10\n",
       "12       0.026123      0.000677         0.002000        0.000153        0.01  {'alpha': 0.01}          -0.044695          -0.044503          -0.044340          -0.044349          -0.044325        -0.044442        0.000142               11"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get alphas\n",
    "params={'alpha': [25,10,4,2,1.0,0.8,0.5,0.3,0.2,0.1,0.05,0.02,0.01]}\n",
    "ridge_model = Ridge()\n",
    "ridge_clf = GridSearchCV(ridge_model,params,cv=5,verbose = 1, scoring = 'neg_mean_squared_error')\n",
    "ridge_clf.fit(X_train_poly_const,y_train)\n",
    "\n",
    "ridge_clf.best_params_\n",
    "\n",
    "pd.DataFrame(ridge_clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot alphas\n",
    "plt.plot(ridge_clf.cv_results_['param_alpha'], ridge_clf.cv_results_['mean_test_score']*-1)\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Lasso Regularization Coefficient Optimization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  65 out of  65 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.044771</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>25</td>\n",
       "      <td>{'alpha': 25}</td>\n",
       "      <td>-0.048357</td>\n",
       "      <td>-0.048165</td>\n",
       "      <td>-0.048063</td>\n",
       "      <td>-0.048232</td>\n",
       "      <td>-0.048151</td>\n",
       "      <td>-0.048194</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.040268</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "      <td>-0.048357</td>\n",
       "      <td>-0.048165</td>\n",
       "      <td>-0.048063</td>\n",
       "      <td>-0.048232</td>\n",
       "      <td>-0.048151</td>\n",
       "      <td>-0.048194</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.041512</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>4</td>\n",
       "      <td>{'alpha': 4}</td>\n",
       "      <td>-0.048357</td>\n",
       "      <td>-0.048165</td>\n",
       "      <td>-0.048063</td>\n",
       "      <td>-0.048232</td>\n",
       "      <td>-0.048151</td>\n",
       "      <td>-0.048194</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.041418</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.002210</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>2</td>\n",
       "      <td>{'alpha': 2}</td>\n",
       "      <td>-0.048357</td>\n",
       "      <td>-0.048165</td>\n",
       "      <td>-0.048063</td>\n",
       "      <td>-0.048232</td>\n",
       "      <td>-0.048151</td>\n",
       "      <td>-0.048194</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041158</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.002095</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>-0.048357</td>\n",
       "      <td>-0.048165</td>\n",
       "      <td>-0.048063</td>\n",
       "      <td>-0.048232</td>\n",
       "      <td>-0.048151</td>\n",
       "      <td>-0.048194</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.042054</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.002286</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'alpha': 0.8}</td>\n",
       "      <td>-0.048357</td>\n",
       "      <td>-0.048165</td>\n",
       "      <td>-0.048063</td>\n",
       "      <td>-0.048232</td>\n",
       "      <td>-0.048151</td>\n",
       "      <td>-0.048194</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.040024</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>-0.048357</td>\n",
       "      <td>-0.048165</td>\n",
       "      <td>-0.048063</td>\n",
       "      <td>-0.048232</td>\n",
       "      <td>-0.048151</td>\n",
       "      <td>-0.048194</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.043977</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 0.3}</td>\n",
       "      <td>-0.048357</td>\n",
       "      <td>-0.048165</td>\n",
       "      <td>-0.048063</td>\n",
       "      <td>-0.048232</td>\n",
       "      <td>-0.048151</td>\n",
       "      <td>-0.048194</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.041933</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'alpha': 0.2}</td>\n",
       "      <td>-0.048357</td>\n",
       "      <td>-0.048165</td>\n",
       "      <td>-0.048063</td>\n",
       "      <td>-0.048232</td>\n",
       "      <td>-0.048151</td>\n",
       "      <td>-0.048194</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.040603</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>-0.048357</td>\n",
       "      <td>-0.048165</td>\n",
       "      <td>-0.048063</td>\n",
       "      <td>-0.048232</td>\n",
       "      <td>-0.048151</td>\n",
       "      <td>-0.048194</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.043589</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'alpha': 0.05}</td>\n",
       "      <td>-0.048357</td>\n",
       "      <td>-0.048165</td>\n",
       "      <td>-0.048063</td>\n",
       "      <td>-0.048232</td>\n",
       "      <td>-0.048151</td>\n",
       "      <td>-0.048194</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.041999</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.02</td>\n",
       "      <td>{'alpha': 0.02}</td>\n",
       "      <td>-0.048357</td>\n",
       "      <td>-0.048165</td>\n",
       "      <td>-0.048063</td>\n",
       "      <td>-0.048232</td>\n",
       "      <td>-0.048151</td>\n",
       "      <td>-0.048194</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.040706</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>-0.048357</td>\n",
       "      <td>-0.048165</td>\n",
       "      <td>-0.048063</td>\n",
       "      <td>-0.048232</td>\n",
       "      <td>-0.048151</td>\n",
       "      <td>-0.048194</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha           params  split0_test_score  split1_test_score  split2_test_score  split3_test_score  split4_test_score  mean_test_score  std_test_score  rank_test_score\n",
       "0        0.044771      0.002269         0.002557        0.000482          25    {'alpha': 25}          -0.048357          -0.048165          -0.048063          -0.048232          -0.048151        -0.048194        0.000098                1\n",
       "1        0.040268      0.002029         0.002092        0.000128          10    {'alpha': 10}          -0.048357          -0.048165          -0.048063          -0.048232          -0.048151        -0.048194        0.000098                1\n",
       "2        0.041512      0.001348         0.002194        0.000247           4     {'alpha': 4}          -0.048357          -0.048165          -0.048063          -0.048232          -0.048151        -0.048194        0.000098                1\n",
       "3        0.041418      0.001204         0.002210        0.000302           2     {'alpha': 2}          -0.048357          -0.048165          -0.048063          -0.048232          -0.048151        -0.048194        0.000098                1\n",
       "4        0.041158      0.001392         0.002095        0.000163           1   {'alpha': 1.0}          -0.048357          -0.048165          -0.048063          -0.048232          -0.048151        -0.048194        0.000098                1\n",
       "5        0.042054      0.001238         0.002286        0.000307         0.8   {'alpha': 0.8}          -0.048357          -0.048165          -0.048063          -0.048232          -0.048151        -0.048194        0.000098                1\n",
       "6        0.040024      0.001310         0.002106        0.000146         0.5   {'alpha': 0.5}          -0.048357          -0.048165          -0.048063          -0.048232          -0.048151        -0.048194        0.000098                1\n",
       "7        0.043977      0.000746         0.002224        0.000152         0.3   {'alpha': 0.3}          -0.048357          -0.048165          -0.048063          -0.048232          -0.048151        -0.048194        0.000098                1\n",
       "8        0.041933      0.002492         0.002239        0.000216         0.2   {'alpha': 0.2}          -0.048357          -0.048165          -0.048063          -0.048232          -0.048151        -0.048194        0.000098                1\n",
       "9        0.040603      0.001045         0.002001        0.000076         0.1   {'alpha': 0.1}          -0.048357          -0.048165          -0.048063          -0.048232          -0.048151        -0.048194        0.000098                1\n",
       "10       0.043589      0.002983         0.002447        0.000341        0.05  {'alpha': 0.05}          -0.048357          -0.048165          -0.048063          -0.048232          -0.048151        -0.048194        0.000098                1\n",
       "11       0.041999      0.001790         0.002348        0.000152        0.02  {'alpha': 0.02}          -0.048357          -0.048165          -0.048063          -0.048232          -0.048151        -0.048194        0.000098                1\n",
       "12       0.040706      0.001425         0.002023        0.000129        0.01  {'alpha': 0.01}          -0.048357          -0.048165          -0.048063          -0.048232          -0.048151        -0.048194        0.000098                1"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get alphas\n",
    "params={'alpha': [25,10,4,2,1.0,0.8,0.5,0.3,0.2,0.1,0.05,0.02,0.01]}\n",
    "lasso_model = Lasso()\n",
    "lasso_clf = GridSearchCV(lasso_model,params,cv=5,verbose = 1, scoring = 'neg_mean_squared_error')\n",
    "lasso_clf.fit(X_train_poly_const,y_train)\n",
    "\n",
    "lasso_clf.best_params_\n",
    "\n",
    "pd.DataFrame(lasso_clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat function to optimize and explore lasso and ridge\n",
    "def fit_reg(Xtrain, ytrain, model=LassoCV, cv_list = list(range(3,10)), alphas = [0.001, .01, .05, .1, .5, 1, 2, 5, 10, 50, 100, 500], scoring = 'neg_mean_squared_error'):\n",
    "    d = {'cv': [], 'mse': []}\n",
    "    best_mse = 100\n",
    "    best_cv = 0\n",
    "    best_model = None\n",
    "    if model == LassoCV:\n",
    "        ytrain = np.ravel(ytrain)\n",
    "    for cv in cv_list:\n",
    "        temp_model = model(cv = cv)\n",
    "        scores = -1 * cross_val_score(temp_model, Xtrain, ytrain, scoring = scoring, cv=cv)\n",
    "        d['cv'].append(cv)\n",
    "        d['mse'].append(scores.mean())\n",
    "        if scores.mean() < best_mse:\n",
    "            best_mse = scores.mean()\n",
    "            best_cv = cv\n",
    "            best_model = temp_model\n",
    "    print(\"best_model:\", best_model, \"yielded MSE of:\", best_mse)\n",
    "    return [best_model, d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model: LassoCV(alphas=None, copy_X=True, cv=6, eps=0.001, fit_intercept=True,\n",
      "        max_iter=1000, n_alphas=100, n_jobs=None, normalize=False,\n",
      "        positive=False, precompute='auto', random_state=None,\n",
      "        selection='cyclic', tol=0.0001, verbose=False) yielded MSE of: 0.04443519962908655\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.044435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.044439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.044442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.044435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.044439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>0.044439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>0.044443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cv       mse\n",
       "0   3  0.044435\n",
       "1   4  0.044439\n",
       "2   5  0.044442\n",
       "3   6  0.044435\n",
       "4   7  0.044439\n",
       "5   8  0.044439\n",
       "6   9  0.044443"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get training\n",
    "lasso = fit_reg(X_train_poly_const, y_train)\n",
    "pd.DataFrame(lasso[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/cs109a/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:1100: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "//anaconda3/envs/cs109a/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:1100: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "//anaconda3/envs/cs109a/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:1100: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "//anaconda3/envs/cs109a/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:1100: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "//anaconda3/envs/cs109a/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:1100: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "//anaconda3/envs/cs109a/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:1100: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04519956280964759"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get test\n",
    "scores = -1 * cross_val_score(lasso[0], X_test_poly_const, y_test, scoring = 'neg_mean_squared_error', cv=6)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model: RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=6, fit_intercept=True,\n",
      "        gcv_mode=None, normalize=False, scoring=None, store_cv_values=False) yielded MSE of: 0.04443220746050943\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.044433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.044436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.044439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.044432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.044436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>0.044436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>0.044441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cv       mse\n",
       "0   3  0.044433\n",
       "1   4  0.044436\n",
       "2   5  0.044439\n",
       "3   6  0.044432\n",
       "4   7  0.044436\n",
       "5   8  0.044436\n",
       "6   9  0.044441"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get training\n",
    "ridge = fit_reg(X_train_poly_const, y_train, model = RidgeCV)\n",
    "pd.DataFrame(ridge[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04569179718349906"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get test\n",
    "scores = -1 * cross_val_score(ridge[0], X_test_poly_const, y_test, scoring = 'neg_mean_squared_error', cv=6)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add interaction terms to dataset\n",
    "X_train_int = X_train.copy()\n",
    "X_test_int = X_test.copy()\n",
    "for first_col in X_train.columns:\n",
    "    for second_col in X_train.columns.drop(first_col):\n",
    "        X_train_int[first_col + \"*\" + second_col] = X_train[first_col]*X_train[second_col]\n",
    "        X_test_int[first_col + \"*\" + second_col] = X_test[first_col]*X_test[second_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training MSE</th>\n",
       "      <th>Test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear</td>\n",
       "      <td>0.045106</td>\n",
       "      <td>0.045137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear w/ 2nd Degree Poly</td>\n",
       "      <td>0.044413</td>\n",
       "      <td>0.044654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso w/ 2nd Degree Poly</td>\n",
       "      <td>0.044435</td>\n",
       "      <td>0.045200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge w/ 2nd Degree Poly</td>\n",
       "      <td>0.044432</td>\n",
       "      <td>0.045692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Training MSE  Test MSE\n",
       "0                     Linear      0.045106  0.045137\n",
       "1  Linear w/ 2nd Degree Poly      0.044413  0.044654\n",
       "2   Lasso w/ 2nd Degree Poly      0.044435  0.045200\n",
       "3   Ridge w/ 2nd Degree Poly      0.044432  0.045692"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile\n",
    "pd.DataFrame([[\"Linear\", train_score, test_score],[\"Linear w/ 2nd Degree Poly\", train_score_poly, test_score_poly],[\"Lasso w/ 2nd Degree Poly\",0.044435,0.045200],[\"Ridge w/ 2nd Degree Poly\",0.044432,0.045692]], columns = ['Model', 'Training MSE', 'Test MSE'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
